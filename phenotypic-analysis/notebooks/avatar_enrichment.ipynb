{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease enrichment analysis of phenotypic avatars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhpo import Ontology, HPOSet, Omim\n",
    "from pyhpo import stats as hpostats\n",
    "from typing import List, Tuple, Set\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import calc_similarity as cs\n",
    "from scipy import stats\n",
    "import ray\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontology and Avatar loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to initialize the ontology for hpo3 (pyhpo) library (loads packaged HPO and\n",
    "# disease assests into memory); follows a singleton pattern\n",
    "_ = Ontology()\n",
    "\n",
    "mecfs_pheno_file = Path(\"../data/mecfs-phenotypes.tsv\")\n",
    "mecfs_phenos = cs.load_phenos_by_group(str(mecfs_pheno_file))\n",
    "all_pheno_profiles = cs.get_mecfs_pheno_combos(mecfs_phenos)\n",
    "pene_hposet = HPOSet.from_queries(mecfs_phenos[\"PENE\"])\n",
    "mecfs_hposet = HPOSet.from_queries([p for subcat in mecfs_phenos.values() for p in subcat])\n",
    "\n",
    "# add PENE phenotypes to all MECFS avatars as that is a manditory feature\n",
    "for pheno_profile in all_pheno_profiles:\n",
    "    pheno_profile.extend(mecfs_phenos[\"PENE\"])\n",
    "\n",
    "mecfs_hposet_avatars = [HPOSet.from_queries(p) for p in all_pheno_profiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease Enrichment Analysis\n",
    "\n",
    "HPO3 has a built-in disease enrichment calculation but it doesn't appear to support a process for correcting for multiple hypothesis testing (MHT),\n",
    "at least as of the writing of this analysis. Implementing an erichment analysis (a.k.a. over representation analysis) to include correction for\n",
    "MHT can be done in a straight forward manner. Having the p-values for all of the disease enrichment tests allows us to apply the\n",
    "Benjamini and Hochberg (BH) correction process for controlling the false discovery rate. However, the HPO3 disease enrichment function only returns\n",
    "the enriched diseases (p-value < 0.05) and the BH correction needs the p-values from all tests, not just the significant results. Thus, we have to\n",
    "implement the disease enrichment procedure ourselves and then perform the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build background set of phenotypes (count), only focusing on non-modifier terms\n",
    "# (i.e., terms that are children of HP:0000118 | Phenotypic abnormality)\n",
    "total_phenos_count = 0\n",
    "pheno_abnormality_term = Ontology.get_hpo_object(\"HP:0000118\")\n",
    "for term in Ontology:\n",
    "    if pheno_abnormality_term in term.all_parents:\n",
    "        total_phenos_count += 1\n",
    "\n",
    "# create disease list where only non-modifier terms are used for describing the disease,\n",
    "# for same reason we restrict the \"Phenotypic abnormality\" subsection of the ontology above\n",
    "omim_id_only_nonmod_phenos = [(disease.name, set(disease.hpo_set().remove_modifier().serialize().split(\"+\"))) for disease in Ontology.omim_diseases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a single function to compute the disease enrichment and BH correction for an MECFS avatar and use the python Ray library to facilitate parallelization (we'll need to perform this process for 110,160 avatars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def get_hypergeom_enrich(\n",
    "    query_id: str,\n",
    "    query: Set[str],\n",
    "    diseases: List[Tuple[str, Set[str]]],\n",
    "    total_phenos_count: int,\n",
    "    alpha: float = 0.05,\n",
    ") -> Tuple[str, List[Tuple[str, float, float]]]:\n",
    "    # setup one time computation values for contingency table\n",
    "    N = len(query)\n",
    "    M = total_phenos_count\n",
    "\n",
    "    # for each disease in the ontology build a contingency table\n",
    "    # and compute one-sided Fisher's exact test (again, only using non-modifier phenotypes of the disease)\n",
    "    raw_pvals = []\n",
    "    for disease in diseases:\n",
    "        # contingency table format\n",
    "        # _____________________|_Query Phenotypes_|_Nonquery Phenotypes_|\n",
    "        # Disease Phenotypes   |        x         |        n - x        |\n",
    "        # Nondisease Phenotypes|      N - x       |    M - (n+N) + x    |\n",
    "        #\n",
    "        # x = count of phenotypes shared between the query phenotype set and the disease phenotype set\n",
    "        # N = count of phenotypes in the query phenotype set\n",
    "        # n = count of phenotypes in the disease phenotype set\n",
    "        # M = count of all possible phenotypes that a disease or query phenotype set could have\n",
    "        x = len(disease[1].intersection(query))\n",
    "        n = len(disease[1])\n",
    "        table = np.array([[x, n - x], [N - x, M - (n + N) + x]])\n",
    "        raw_pvals.append(stats.fisher_exact(table, alternative=\"greater\").pvalue)\n",
    "\n",
    "    # apply Benjamini-Hochberg Procedure to adjust for multiple hypothesis testing\n",
    "    adj_pvals = stats.false_discovery_control(raw_pvals)\n",
    "    # filter for significantly enriched diseases after corretion for MHT\n",
    "    sig_enrich = [(disease[0], raw_pval, adj_pval) for disease, raw_pval, adj_pval in zip(diseases, raw_pvals, adj_pvals) if adj_pval < alpha]\n",
    "    return (\n",
    "        query_id,\n",
    "        sig_enrich\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrichment calculation comparison\n",
    "\n",
    "Start Ray instance locally for running computation in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 15:27:37,095\tINFO worker.py:2013 -- Started a local Ray instance.\n",
      "/Users/brandon/miniforge3/envs/mecfs-pheno/lib/python3.10/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9806161ed54d2d965f9403eb597865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.10.19</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.50.1</b></td>\n",
       "    </tr>\n",
       "    \n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.19', ray_version='2.50.1', ray_commit='7cf6817996f5304b5c808453a997fc1570dcde25')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare our enrichment calulations to the established process from the HPO3 to ensure we didn't make any mistakes in the procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core PENE enriched diseases: 56, MECFS all phenos enriched diseases: 2413\n",
      "Core PENE enriched diseases: 56, MECFS all phenos enriched diseases: 731\n"
     ]
    }
   ],
   "source": [
    "# test for enrichment using the PENE MECFS phenotypes list and the complete set of MECFS phenotypes using HPO3 stats package\n",
    "model = hpostats.EnrichmentModel(\"omim\")\n",
    "pene_pyhpo_enrich = model.enrichment(\"hypergeom\", pene_hposet)\n",
    "mecfs_pyhpo_enrich = model.enrichment(\"hypergeom\", mecfs_hposet)\n",
    "print(f\"Core PENE enriched diseases: {len(pene_pyhpo_enrich)}, MECFS all phenos enriched diseases: {len(mecfs_pyhpo_enrich)}\")\n",
    "\n",
    "# test the same using our reimplimentation\n",
    "task_handles = [\n",
    "    get_hypergeom_enrich.remote(\"PENE\", set(pene_hposet.remove_modifier().serialize().split(\"+\")), omim_id_only_nonmod_phenos, total_phenos_count, alpha=1.01),\n",
    "    get_hypergeom_enrich.remote(\"MECFS\", set(mecfs_hposet.remove_modifier().serialize().split(\"+\")), omim_id_only_nonmod_phenos, total_phenos_count, alpha=1.01)\n",
    "]\n",
    "task_results = ray.get(task_handles)\n",
    "pene_custom_enrich_cnt = sum(1 for testres in task_results[0][1] if testres[1] < 0.05)\n",
    "mecfs_custom_enrich_cnt = sum(1 for testres in task_results[1][1] if testres[1] < 0.05)\n",
    "print(f\"Core PENE enriched diseases: {pene_custom_enrich_cnt}, MECFS all phenos enriched diseases: {mecfs_custom_enrich_cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same enrichment results when considering just the smaller list of the core MECFS PENE phenotypes but different when considering the larger MECFS phenotype set. Closer inspection of HPO3 shows that the disease enrichement test doesn't limit to the subset of phenotypes under `Phenotypic abnormality` like the custome function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avatar Disease Enrichment with BH correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2530 MiB, 1885 objects, write throughput 284 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 4099 MiB, 3053 objects, write throughput 257 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 8195 MiB, 6103 objects, write throughput 241 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 16385 MiB, 12201 objects, write throughput 240 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 32774 MiB, 24403 objects, write throughput 257 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 65542 MiB, 48801 objects, write throughput 269 MiB/s.\n",
      "\u001b[36m(raylet)\u001b[0m Spilled 131073 MiB, 97592 objects, write throughput 244 MiB/s.\n"
     ]
    }
   ],
   "source": [
    "# schedule avatar disease enrichment computation with running Ray instance\n",
    "# note: this schedules 110,160 enrichment tasks to be run and Ray uses all available\n",
    "# resources to complete tasks, you have been notified\n",
    "dis_enrich_tasks = []\n",
    "for idx, avatar in enumerate(mecfs_hposet_avatars):\n",
    "    dis_enrich_tasks.append(get_hypergeom_enrich.remote(f\"Avatar {idx}\", set(avatar.remove_modifier().serialize().split(\"+\")), omim_id_only_nonmod_phenos, total_phenos_count))\n",
    "\n",
    "# ask Ray to get results from all enrichment tasks,\n",
    "# returned in a list with the same order as the scheduled tasks\n",
    "# this will take ~4.5 hours on a 16-core 32GB RAM machine \n",
    "enriched_dis_per_avatar = ray.get(dis_enrich_tasks)\n",
    "\n",
    "# write findings to file for backup and later use\n",
    "enrich_res_file = Path(\"../data/results/mecfs-avatars-disease-enrichment.tsv\")\n",
    "with enrich_res_file.open(\"wt\") as outfile:\n",
    "    outfile.write(\"Avatar ID\\tDisease\\tp-value\\tadj. p-value\\n\")\n",
    "    for enrich_res in enriched_dis_per_avatar:\n",
    "        avatar_id = enrich_res[0]\n",
    "        for enrich_dis_res in enrich_res[1]:\n",
    "            formatted_output = [avatar_id, enrich_dis_res[0], f\"{enrich_dis_res[1]:.14f}\", f\"{enrich_dis_res[2]:.14f}\"]\n",
    "            outfile.write(\"\\t\".join(formatted_output) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the compute is done we can shutdown the Ray instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease Ranking\n",
    "\n",
    "Since the number of avatars in which a disease is enriched and the enrichment score is variable we need a ranking scheme that will account for these factors when producing an overall rank of enriched diseases. For this process we leverage a weighted version of the [mean reciprical rank](https://en.wikipedia.org/wiki/Mean_reciprocal_rank). The weight is derived from the number of avatars which a given disease was phenotypicially significantly enriched for. Some diseases are significantly enriched for a subset of avatars, but enrich highly for that subset. The weighting helps rank those diseases higher in the overall ranking over diseases that enrich for more avatars but not as highly.\n",
    "\n",
    "**NOTE:** see data/weighted-ranking-demo.xlsx for a walkthrough of the calculation to weight the median reciprical ranks for ranking diseases best matching MECFS phenotypic avatars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# format data into pandas dataframe\n",
    "enrich_res_file = Path(\"../data/results/mecfs-avatars-disease-enrichment.tsv\")\n",
    "enrich_df = pd.read_table(enrich_res_file, index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the reciprical of the rank for each disease for each avatar and store with other information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# group by avatar and store reciprical of the rank for each disease within that avatar\n",
    "enrich_df[\"in_avatar_recip_rank\"] = 1.0/enrich_df.groupby(\"Avatar ID\")[\"adj. p-value\"].rank(\"first\")\n",
    "\n",
    "# compute the mean reciprical rank per disease\n",
    "res_df = enrich_df.groupby(\"Disease\")[[\"in_avatar_recip_rank\"]].mean()\n",
    "res_df.rename(columns={\"in_avatar_recip_rank\": \"mrr\"}, inplace=True)\n",
    "\n",
    "# Calculate the weight (the percentage impact to the weighted average), the\n",
    "# weighting strategy is based on this answer https://math.stackexchange.com/a/1577209 to a similar problem.\n",
    "# This computes weights for helping with ranking by accounting for difference in number of avatars\n",
    "# each disease is enriched in.\n",
    "avatar_cnt_df = enrich_df.groupby(\"Disease\").count().rename(columns={\"Avatar ID\": \"avatar_cnt\"}).drop(columns=[\"p-value\", \"adj. p-value\", \"in_avatar_recip_rank\"])\n",
    "avatar_cnt_df[\"percent_enriched\"] = avatar_cnt_df[\"avatar_cnt\"]/110160.0\n",
    "mean_percent_positive = avatar_cnt_df[\"percent_enriched\"].mean()\n",
    "avatar_cnt_df[\"raw_weight\"] = (\n",
    "    (avatar_cnt_df[\"percent_enriched\"] - mean_percent_positive)\n",
    "    * (avatar_cnt_df[\"avatar_cnt\"] / (len(avatar_cnt_df) * 110160.0))\n",
    "    / mean_percent_positive\n",
    ")\n",
    "\n",
    "# the raw weights will be centered around zero, we need to rescale them between zero and one\n",
    "# to appropriately apply the weights to the MRR\n",
    "avatar_cnt_df['scaled_weight'] = (avatar_cnt_df['raw_weight'] - avatar_cnt_df['raw_weight'].min()) / (avatar_cnt_df['raw_weight'].max() - avatar_cnt_df['raw_weight'].min())\n",
    "\n",
    "# bring everything together and compute the weighted MRR\n",
    "res_merged_df = pd.merge(res_df, avatar_cnt_df, how=\"inner\", on=\"Disease\")\n",
    "res_merged_df = res_merged_df.reset_index()\n",
    "res_merged_df[\"weighted_mrr\"] = res_merged_df[\"mrr\"] * res_merged_df[\"scaled_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add some support functions for easy formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add OMIM object to primary findings df for efficient lookup\n",
    "def omim_lookup_by_name(disease):\n",
    "    for omim_dis in Ontology.omim_diseases:\n",
    "        if omim_dis.name == disease:\n",
    "            return omim_dis\n",
    "        \n",
    "\n",
    "def omim_lookup_by_id(omim_id):\n",
    "    return Omim.get(omim_id)\n",
    "\n",
    "\n",
    "# highlighting function for rows in output\n",
    "def highlight_row(row):\n",
    "    enrich_dis = omim_lookup_by_name(row[\"Disease\"])\n",
    "    if enrich_dis in findings_disease_set:\n",
    "        return [\"background-color: lightblue\"] * len(row)\n",
    "\n",
    "    return [\"\"] * len(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add highlighting of diseases found in participants in cohort in the list of enriched diseases found by the avatar analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty up dataframe for final output\n",
    "col_names = {\n",
    "    \"weighted_mrr\": \"Weighted Mean Reciprical Rank\",\n",
    "    \"avatar_cnt\": \"# Avatars Enriched In\",\n",
    "    \"mrr\": \"Mean Reciprical Rank\",\n",
    "    \"scaled_weight\": \"Weight\"\n",
    "}\n",
    "output_df = res_merged_df[[\"Disease\", *col_names.keys()]].copy()\n",
    "output_df.rename(columns=col_names, inplace=True)\n",
    "output_df.sort_values(\"Weighted Mean Reciprical Rank\", inplace=True, ascending=False)\n",
    "output_df[\"Rank\"] = output_df[\"Weighted Mean Reciprical Rank\"].rank(ascending=False)\n",
    "\n",
    "# load disease info from table 1\n",
    "primary_disease_info = pd.read_excel(\n",
    "    \"../data/mecfs-samples/primary-disease-info.xlsx\"\n",
    ")\n",
    "\n",
    "findings_disease_set = set(primary_disease_info[\"OMIM\"].apply(omim_lookup_by_id).to_list())\n",
    "\n",
    "# apply styling per row\n",
    "styled_df = output_df.style.apply(highlight_row, axis=1)\n",
    "\n",
    "# write to excel file for supp.\n",
    "styled_df.to_excel(\n",
    "    \"../data/results/Supp. Table - MECFS avatars and ranked disease enrichment table.xlsx\",\n",
    "    index=False,\n",
    "    columns=[\n",
    "        \"Rank\",\n",
    "        \"Disease\",\n",
    "        \"Weighted Mean Reciprical Rank\", \n",
    "        \"# Avatars Enriched In\", \n",
    "        \"Mean Reciprical Rank\", \n",
    "        \"Weight\"\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Enrichment analysis of Participants\n",
    "\n",
    "In the same fashion as the disease enrichment analysis of the ME/CFS avatars we can perform the calculations based on the phenotypes of the cohort's participants.\n",
    "\n",
    "## Participant Disease Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for reading participant phenotypes from file\n",
    "def parse_n_clean_phenos(participant_phenos: str) -> HPOSet:\n",
    "    return HPOSet.from_queries(participant_phenos.replace(\" \", \"\").split(\",\"))\n",
    "\n",
    "\n",
    "data_path = \"../data/mecfs-samples/patient_hpo_summaries.csv\"\n",
    "participant_phenos = []\n",
    "with open(data_path, \"r\", newline=\"\") as fp:\n",
    "    reader = csv.DictReader(fp)\n",
    "    for row in reader:\n",
    "        participant_phenos.append(\n",
    "            (row[\"Paper_ID\"], parse_n_clean_phenos(row[\"HPO_Terms\"]))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just like we did with the avatars we can ship the enrichment process off to Ray and let it do it quickly in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy developer copy and variable renaming from above (I know a generic function could be used here but the analysis doesn't warrant the time to make it so)\n",
    "# schedule participant disease enrichment computation with running Ray instance\n",
    "# note: this schedules 31 enrichment tasks to be run and Ray uses all available\n",
    "# resources to complete tasks, you have been notified\n",
    "dis_enrich_tasks = []\n",
    "for idx, part_phenos in participant_phenos:\n",
    "    dis_enrich_tasks.append(get_hypergeom_enrich.remote(f\"{idx}\", set(part_phenos.remove_modifier().serialize().split(\"+\")), omim_id_only_nonmod_phenos, total_phenos_count))\n",
    "\n",
    "# ask Ray to get results from all enrichment tasks,\n",
    "# returned in a list with the same order as the scheduled tasks\n",
    "# this will only take a few seconds on a 16-core 32GB RAM machine\n",
    "enriched_dis_per_participant = ray.get(dis_enrich_tasks)\n",
    "\n",
    "# write findings to file for backup and later use\n",
    "enrich_res_file = Path(\"../data/results/participants-disease-enrichment.tsv\")\n",
    "with enrich_res_file.open(\"wt\") as outfile:\n",
    "    outfile.write(\"Participant ID\\tDisease\\tp-value\\tadj. p-value\\n\")\n",
    "    for enrich_res in enriched_dis_per_participant:\n",
    "        p_id = enrich_res[0]\n",
    "        for enrich_dis_res in enrich_res[1]:\n",
    "            formatted_output = [p_id, enrich_dis_res[0], f\"{enrich_dis_res[1]:.14f}\", f\"{enrich_dis_res[2]:.14f}\"]\n",
    "            outfile.write(\"\\t\".join(formatted_output) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant Disease Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# group by participant and store reciprical of the rank for each disease within that participant\n",
    "enrich_df = pd.read_table(enrich_res_file)\n",
    "enrich_df[\"in_participant_recip_rank\"] = 1.0/enrich_df.groupby(\"Participant ID\")[\"adj. p-value\"].rank(\"first\")\n",
    "\n",
    "# compute the mean reciprical rank per disease\n",
    "res_df = enrich_df.groupby(\"Disease\")[[\"in_participant_recip_rank\"]].mean()\n",
    "res_df.rename(columns={\"in_participant_recip_rank\": \"mrr\"}, inplace=True)\n",
    "\n",
    "# Calculate the weight (the percentage impact to the weighted average), the\n",
    "# weighting strategy is based on this answer https://math.stackexchange.com/a/1577209 to a similar problem.\n",
    "# This computes weights for helping with ranking by accounting for difference in number of participants\n",
    "# each disease is enriched in.\n",
    "participant_cnt_df = enrich_df.groupby(\"Disease\").count().rename(columns={\"Participant ID\": \"participant_cnt\"}).drop(columns=[\"p-value\", \"adj. p-value\", \"in_participant_recip_rank\"])\n",
    "participant_cnt_df[\"percent_enriched\"] = participant_cnt_df[\"participant_cnt\"]/110160.0\n",
    "mean_percent_positive = participant_cnt_df[\"percent_enriched\"].mean()\n",
    "participant_cnt_df[\"raw_weight\"] = (\n",
    "    (participant_cnt_df[\"percent_enriched\"] - mean_percent_positive)\n",
    "    * (participant_cnt_df[\"participant_cnt\"] / (len(participant_cnt_df) * 110160.0))\n",
    "    / mean_percent_positive\n",
    ")\n",
    "\n",
    "# the raw weights will be centered around zero, we need to rescale them between zero and one\n",
    "# to appropriately apply the weights to the MRR\n",
    "participant_cnt_df['scaled_weight'] = (participant_cnt_df['raw_weight'] - participant_cnt_df['raw_weight'].min()) / (participant_cnt_df['raw_weight'].max() - participant_cnt_df['raw_weight'].min())\n",
    "\n",
    "# bring everything together and compute the weighted MRR\n",
    "res_merged_df = pd.merge(res_df, participant_cnt_df, how=\"inner\", on=\"Disease\")\n",
    "res_merged_df = res_merged_df.reset_index()\n",
    "res_merged_df[\"weighted_mrr\"] = res_merged_df[\"mrr\"] * res_merged_df[\"scaled_weight\"]\n",
    "\n",
    "# pretty up dataframe for final output\n",
    "col_names = {\n",
    "    \"weighted_mrr\": \"Weighted Mean Reciprical Rank\",\n",
    "    \"participant_cnt\": \"# Participants Enriched In\",\n",
    "    \"mrr\": \"Mean Reciprical Rank\",\n",
    "    \"scaled_weight\": \"Weight\"\n",
    "}\n",
    "output_df = res_merged_df[[\"Disease\", *col_names.keys()]].copy()\n",
    "output_df.rename(columns=col_names, inplace=True)\n",
    "output_df.sort_values(\"Weighted Mean Reciprical Rank\", inplace=True, ascending=False)\n",
    "output_df[\"Rank\"] = output_df[\"Weighted Mean Reciprical Rank\"].rank(ascending=False)\n",
    "\n",
    "# load disease info from table 1\n",
    "primary_disease_info = pd.read_excel(\n",
    "    \"../data/mecfs-samples/primary-disease-info.xlsx\"\n",
    ")\n",
    "\n",
    "# add OMIM object to primary findings df for efficient lookup\n",
    "def omim_lookup_by_name(disease):\n",
    "    for omim_dis in Ontology.omim_diseases:\n",
    "        if omim_dis.name == disease:\n",
    "            return omim_dis\n",
    "        \n",
    "\n",
    "def omim_lookup_by_id(omim_id):\n",
    "    return Omim.get(omim_id)\n",
    "\n",
    "\n",
    "findings_disease_set = set(primary_disease_info[\"OMIM\"].apply(omim_lookup_by_id).to_list())\n",
    "\n",
    "# highlighting function for rows in output\n",
    "def highlight_row(row):\n",
    "    enrich_dis = omim_lookup_by_name(row[\"Disease\"])\n",
    "    if enrich_dis in findings_disease_set:\n",
    "        return [\"background-color: lightblue\"] * len(row)\n",
    "\n",
    "    return [\"\"] * len(row)\n",
    "\n",
    "# apply styling per row\n",
    "styled_df = output_df.style.apply(highlight_row, axis=1)\n",
    "\n",
    "# write to excel file for supp.\n",
    "styled_df.to_excel(\n",
    "    \"../data/results/Supp. Table - MECFS participants ranked disease enrichment table.xlsx\",\n",
    "    index=False,\n",
    "    columns=[\n",
    "        \"Rank\",\n",
    "        \"Disease\",\n",
    "        \"Weighted Mean Reciprical Rank\", \n",
    "        \"# Participants Enriched In\", \n",
    "        \"Mean Reciprical Rank\", \n",
    "        \"Weight\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762896573.102194 10089496 chttp2_transport.cc:1182] ipv4:127.0.0.1:60878: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {file:\"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/transport/chttp2_transport.cc\", file_line:1171, created_time:\"2025-11-11T15:29:33.102182-06:00\", http2_error:2, grpc_status:14}\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecfs-pheno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
